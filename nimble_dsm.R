# setup and run the DSM using nimble

nimble_dsm <- function(fitted_dsm, obs, segs, cruz, vp){

  # need to define half-normal point transect detection function pdf
  dhnpt <<- nimbleFunction(run = function(x = double(0),
                           b0 = double(0), b1 = double(0),
                           covar = double(0), width = double(0),
                           log = integer(0, default = 0)) {
    returnType(double(0))

    # calculate scale parameter
    sigma <- exp(b0 + b1*covar)

    # analytic expression for integral of 2*r*g(r)/width^2 when
    #  g(r) is half-normal (Intro distance book eqn 3.45)
    nu <- sigma^2 * (1 - exp(-(width^2)/(2*sigma^2)))

    # evaluate the detection function at distance/chaparral combination
    g <- exp(-(x^2)/(2*sigma^2))

    # pdf
    L <- (x * g)/nu

    if(log) return(log(L))
    else return(L)
  })
  rhnpt <<- nimbleFunction(run = function(n = integer(0),
                           b0 = double(0), b1 = double(0),
                           covar = double(0), width = double(0),
                           log = integer(0, default = 0)) {
    returnType(double())
    return(0)
  })
  # register this distribution
  nimble::registerDistributions(list(
    dhnpt = list(BUGSdist="dhnpt(b0, b1, covar, width)",
                 pqAvail = FALSE,
                 range = c(0, 1000))))


  # nimble code for the full model
  # design and penalty (precision) matrices only need to be setup
  # once (since points are the same each time) so this is hard-coded
  model_code <- nimbleCode({
    # priors on detection function parameters
    # intercept for scale
    beta0 ~ dnorm(0, 0.1)
    # chaparral coef
    beta1 ~ dunif(-2, 0)

    # detection function likelihood
    for(j in 1:n_obs){
      obs_distance[j] ~ dhnpt(beta0, beta1, obs_chaparral[j], width)
    }

    eta[] <- X[,] %*% b[] ## linear predictor

    # build the mean
    for (i in 1:n) {
      # calculate sigma
      sigma_seg[i] <- exp(beta0 + beta1*seg_chaparral[i])
      # calculate effective area for this segment
      # (Intro distance book eqn 3.45)
      nu[i] <- 2 * pi * sigma_seg[i]^2 *
                (1 - exp(-(width^2)/(2*sigma_seg[i]^2)))
      # calculate the mean of the distribution, including nu
      # as the offset
      mu[i] <- exp(log(nu[i]) + eta[i])
      y[i] ~ dpois(mu[i])
    }

    # intercept prior
    b[1] ~ dnorm(0, b1_prec)

    # prior for s(x,y)...
    K1[1:19, 1:19] <- S1[1:19, 1:19] * lambda[1] +
                      S1[1:19, 20:38] * lambda[2]
    b[2:20] ~ dmnorm(zero[2:20], K1[1:19, 1:19])

    # smoothing parameter prior
    for(k in 1:2){
      lambda[k] ~ dgamma(.05,.005)
      rho[k] <- log(lambda[k])
#      rho[k] ~ dunif(-10, 10)
#      lambda[k] <- exp(rho[k])
    }

    # calculate abundance over the prediction grid
    Nhat[] <- areas[]*exp(Lp[, ] %*% b[])
    Nhat_total <- sum(Nhat[])
  })


  # Define parameters to be monitored
  varsToMonitor <- c("Nhat_total", "beta0", "beta1", "rho")

  # MCMC settings
  nitt <- 500000
  burnin <- 100000
  thin <- 50


  # get starting values from jagam
  # generate a safe filename
  jags_fn <- tempfile("jagstemp", tmpdir=".", fileext=".jags")
  # same jagam call was used to generate template JAGS code for smoothers
  # fitted_dsm has the data in the right format
  ll <- jagam(count~s(x,y, k=20, bs="tp"),
              offset=fitted_dsm$data$off.set,
              data=fitted_dsm$data,
              family=poisson, sp.prior="log.uniform",
              file=jags_fn)

  # get the intercept from the JAGS source and delete the temp file
  rl <- readLines(jags_fn)
  unlink(jags_fn)
  b1_prec <- eval(parse(text=sub(" is.*", "", sub(".*=", "", rl[5]))))

  # data for jags is generated by mgcv::jagam()
  # add extra bits here
  nimble_data <- ll$jags.data
  # calculate the Lp matrix (to map coefficients to predictions on
  # linear predictor scale)
  nimble_data$Lp <- predict(fitted_dsm, cruz, type="lpmatrix")
  nimble_data$obs_distance  <- obs$distance
  nimble_data$obs_chaparral <- obs$chaparral
  nimble_data$seg_chaparral <- segs$chaparral
  nimble_data$y             <- fitted_dsm$data$count
  nimble_data$width         <- fitted_dsm$ddf$meta.data$width
  nimble_data$n             <- NULL # actually a const below
  nimble_data$offset       <- NULL # actually a const below

  # define some constants
  nimble_consts <- list(pi      = pi,
                        # intercept prior based on code in mgcv::jagam
                        b1_prec = signif(b1_prec),
                        n_obs   = length(obs$distance),
                        n       = nrow(segs),
                        areas   = cruz$off.set)

  # initial values are found by mgcv::jagam
  # add all here but we will reset in main simulation
  nimble_inits <- ll$jags.ini
  # set initial values to the values from the detection function
  nimble_inits$beta0 <- fitted_dsm$ddf$par[1]
  nimble_inits$beta1 <- fitted_dsm$ddf$par[2]

  # declare variable dimensions when nimble complains
  nimble_dims <- list(b     = length(coef(fitted_dsm)),
                      eta   = nrow(nimble_data$X),
                      Nhat  = nrow(nimble_data$Lp))


  # build and compile the model
  nm <- nimbleModel(model_code, data=nimble_data,
                    constants=nimble_consts,
                    dimensions=nimble_dims)
  # build the MCMC samplers for the compiled model
  my_mcmc <- buildMCMC(nm,
                       monitors=varsToMonitor,
                       thin=thin)
  # compile our model
  nm_cc <- compileNimble(nm)

  # compile the MCMC, using the nm "project"
  cc <- compileNimble(my_mcmc, project=nm)

  # actually do some sampling
  samples <- runMCMC(cc, inits=nimble_inits,
                     niter=nitt, nburnin=burnin)

  return(samples)
}
